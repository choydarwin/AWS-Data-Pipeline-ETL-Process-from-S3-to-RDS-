
# AWS Data Pipeline: ETL Process from S3 to RDS  

## ğŸš€ Overview  
This project demonstrates an **ETL (Extract, Transform, Load) pipeline** using **AWS S3 and RDS**. It focuses on extracting raw data from S3, transforming it using Python, and loading it into a relational database (RDS) for further analysis. The project is designed to showcase my skills in cloud-based data processing and SQL.  

**Note:** The dataset used in this project is sourced from a **Coursera project** 

---

## ğŸ”¹ Technologies Used  
- **AWS S3** â€“ Cloud storage for raw data  
- **AWS RDS (MySQL)** â€“ Relational database for structured data storage  
- **Python** â€“ Data transformation and preprocessing  
- **Pandas** â€“ Data manipulation and cleaning  
- **Boto3** â€“ AWS SDK for interacting with S3 and RDS  
- **SQL** â€“ Database management and querying  

---

## ğŸ”„ ETL Workflow  
1. **Extract** â€“ Retrieve raw data from AWS S3.  
2. **Transform** â€“ Clean, preprocess, and structure data using Python and Pandas.  
   - Missing numeric values were filled with the **median** of the respective column.  
   - Missing categorical values were filled with the **most common data** (mode) of the respective column.  
3. **Load** â€“ Insert processed data into AWS RDS using SQL.  

---

## ğŸ“Œ SQL for Structured Data Management  
SQL is a critical component of this project, enabling structured data management and analysis:  
- **Schema Definition:** SQL scripts create the database schema, ensuring data is organized and accessible.  
- **Data Loading:** SQL `INSERT` statements load the processed data into AWS RDS.  
- **Querying Data:** SQL queries analyze the data, revealing insights and trends.  

---

## ğŸ¯ Key Features  
- âœ”ï¸ **Data Retrieval** â€“ Fetch raw data from AWS S3 using Boto3.  
- âœ”ï¸ **Data Transformation** â€“ Clean and preprocess data using Python and Pandas, including handling missing values.  
- âœ”ï¸ **Data Loading** â€“ Use SQL to create tables and insert processed data into AWS RDS.  
- âœ”ï¸ **Scalability** â€“ Designed for scalability and future improvements.  

---

## ğŸ“Œ Future Enhancements  
- ğŸ”¹ **Advanced SQL Queries** â€“ Implement complex SQL queries for deeper analysis.  
- ğŸ”¹ **Automated Reporting** â€“ Generate automated reports and dashboards using SQL.    
- ğŸ”¹ **Optimization** â€“ Optimize SQL queries and database indexing for better performance.  



